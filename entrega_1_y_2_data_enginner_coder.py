# -*- coding: utf-8 -*-
"""Entrega 1 y 2  Data enginner coder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HcB8eU0PcvHjqZDU4eoRItl2NwebNINI

*ENTREGA* 1
"""

# Instalamos pytrends

pip install pytrends

#Instalamos request

pip install requests

#Instalamos librerias

import pandas as pd
import json
import requests

params = {

"client_id" : "abbae886046b4138812f130e8dd43b81",

"client_secret": "04768c1Da5334DfDa8610395CC31387c"}

response = requests.get("https://apitransporte.buenosaires.gob.ar/colectivos/vehiclePositionsSimple",params = params)

data_json = json.loads(response.content)

df = pd.DataFrame(data_json)

#Realizamos la solicitud

response.content



#Mostramos el dataframe

df

#Importamos libreria para conectar a redshift

!pip install wheel
!pip install pandas
!pip install psycopg2

#Creando conexion a redshift

import psycopg2
url= "jdbc:redshift://data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com:5439/data-engineer-database"
data_base = "data-engineer-database"
user = "ezeale_89_coderhouse"
with open("C:/Users/Usuario/Coder data engineer 2024 /pwd_redshift.txt",'r') as f:
    pwd= f.read()
try:
    conn = psycopg2.connect(
        host="data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com",
        dbname=data_base,
        user=user,
        password=pwd,
        port='5439'
    )
    print("Conectado a Redshift")

except Exception as e:
    print("No es posible conectar a Redshift")
    print(e)

#Crear la tabla, que ya tenemos en el dataframe
with conn.cursor() as cur:
    cur.execute("""
        CREATE TABLE  Colectivos;
        (
      route_id	int (50) primary key,
      latitude	float (100),
      longitude float (100),
      speed float (100),
      timestamp int(100),
      id int (100),
      direction	int(50),
      agency_name	varchar(100),
      agency_id	int(100),
      route_short_name	varchar (200),
      tip_id (100),
      trip_headsign varchar(200)
	           )
    """)
    conn.commit()

#Insertando los datos en Redsfhift
from psycopg2.extras import execute_values
with conn.cursor() as cur:
    execute_values(
        cur,
        '''
        INSERT INTO Datos del colectivo (route_id,latitude,longitude,speed,timestamp,id,direction,agency_name,agency_id,route_short_name,tip_id,trip_headsign)
        VALUES %s
        ''',
        [tuple(row) for row in df.values],
        page_size=len(df)
    )
    conn.commit()



"""ENTREGA 2"""

import requests
import json
import psycopg2
from sqlalchemy import create_engine
import pandas as pd

df

df.head(10)

#Eliminamos datos duplicadoa

df = f = df.drop_duplicates(subset=['route_id','latitude','longitude','speed','timestamp','id','direction','agency_name','agency_id','route_short_name','tip_id','trip_headsign'], keep='first')

# Detectar valores nulos
nulos = df.isnull().sum()

nulos

def conectar_Redshift():
    try:
        conn = psycopg2.connect(
        host="data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com",
        dbname=data_base,
        user=user,
        password=pwd,
        port='5439'
        )
         print("Conectado a Redshift")

def insert_data():
    conn = psycopg2.connect(
            host='data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com',
            dbname=data_base,
            user=user,
            password=pwd,
            port='5439'
        )
    data_dict = get_top_songs()
    df = pd.DataFrame(data_dict)
    #data = [(row['route_id'], row['latitude'], row['longitude'], row['speed'], row['timestamp'], row['id'], row['direction'], row['agency_name'], row['agency_id'], row['route_short'],row['tip_id], row['trip_headsign]  for _, row in df.iterrows()]
    print(df)
    with conn.cursor() as cur:
        try:
            execute_values(
                cur,
                '''
                    INSERT INTO  Datos del colectivo (route_id,latitude,longitude,speed,timestamp,id,direction,agency_name,agency_id,route_short_name,tip_id,trip_headsign)
                    VALUES %s
                    ''',
                    [tuple(row) for row in df.to_numpy()],
                    #data,
                    page_size=len(df)
                )
            conn.commit()
            conn.close()
        except Exception as e:
            print("No es posible insertar datos")
            print(e)













